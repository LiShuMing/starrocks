// This file is licensed under the Elastic License 2.0. Copyright 2021-present, StarRocks Inc.

#include "exec/pipeline/stream_pipeline_driver.h"

#include "common/statusor.h"
#include "exec/pipeline/operator.h"
#include "exec/pipeline/pipeline_driver.h"
#include "exec/pipeline/pipeline_fwd.h"
#include "exec/pipeline/runtime_filter_types.h"
#include "exec/pipeline/scan/morsel.h"
#include "exec/workgroup/work_group.h"
#include "exec/workgroup/work_group_fwd.h"

namespace starrocks::pipeline {

StatusOr<DriverState> StreamPipelineDriver::process(RuntimeState* runtime_state, int worker_id) {
    COUNTER_UPDATE(_schedule_counter, 1);
    SCOPED_TIMER(_active_timer);
    QUERY_TRACE_SCOPED("process", _driver_name);
    set_driver_state(DriverState::RUNNING);
    size_t total_chunks_moved = 0;
    size_t total_rows_moved = 0;
    int64_t time_spent = 0;
    Status return_status = Status::OK();
    DeferOp defer([&]() {
        if (return_status.ok()) {
            _update_statistics(total_chunks_moved, total_rows_moved, time_spent);
        }
    });

    while (true) {
        RETURN_IF_LIMIT_EXCEEDED(runtime_state, "Pipeline");

        size_t num_chunks_moved = 0;
        bool should_yield = false;
        size_t num_operators = _operators.size();
        size_t new_first_unfinished = _first_unfinished;
        size_t new_first_epoch_unfinished = _first_epoch_unfinished;
        for (size_t i = _first_unfinished; i < num_operators - 1; ++i) {
            {
                SCOPED_RAW_TIMER(&time_spent);
                auto& curr_op = _operators[i];
                auto& next_op = _operators[i + 1];

                // Check curr_op finished firstly
                if (UNLIKELY(curr_op->is_finished())) {
                    if (i == 0) {
                        // For source operators
                        RETURN_IF_ERROR(return_status = _mark_operator_finishing(curr_op, runtime_state));
                    }
                    RETURN_IF_ERROR(return_status = _mark_operator_finishing(next_op, runtime_state));
                    new_first_unfinished = i + 1;
                    continue;
                }

                // Check curr_op finished firstly
                if (curr_op->is_epoch_finished()) {
                    if (i == 0) {
                        // For source operators
                        RETURN_IF_ERROR(return_status = _mark_operator_epoch_finishing(curr_op, runtime_state));
                    }
                    RETURN_IF_ERROR(return_status = _mark_operator_epoch_finishing(next_op, runtime_state));
                    new_first_epoch_unfinished = i + 1;
                    continue;
                }

                // try successive operator pairs
                if (!curr_op->has_output() || !next_op->need_input()) {
                    continue;
                }

                if (_check_fragment_is_canceled(runtime_state)) {
                    return _state;
                }

                // pull chunk from current operator and push the chunk onto next
                // operator
                StatusOr<vectorized::ChunkPtr> maybe_chunk;
                {
                    SCOPED_TIMER(curr_op->_pull_timer);
                    QUERY_TRACE_SCOPED(curr_op->get_name(), "pull_chunk");
                    maybe_chunk = curr_op->pull_chunk(runtime_state);
                }
                return_status = maybe_chunk.status();
                if (!return_status.ok() && !return_status.is_end_of_file()) {
                    LOG(WARNING) << "pull_chunk returns not ok status " << return_status.to_string();
                    return return_status;
                }

                if (_check_fragment_is_canceled(runtime_state)) {
                    return _state;
                }

                if (return_status.ok()) {
                    if (maybe_chunk.value() && (maybe_chunk.value()->num_rows() > 0)) {
                        size_t row_num = maybe_chunk.value()->num_rows();
                        total_rows_moved += row_num;
                        {
                            SCOPED_TIMER(next_op->_push_timer);
                            QUERY_TRACE_SCOPED(next_op->get_name(), "push_chunk");
                            return_status = next_op->push_chunk(runtime_state, maybe_chunk.value());
                        }
                        // ignore empty chunk generated by per-tablet computation when query cache enabled
                        if (row_num > 0L) {
                            COUNTER_UPDATE(curr_op->_pull_row_num_counter, row_num);
                            COUNTER_UPDATE(curr_op->_pull_chunk_num_counter, 1);
                            COUNTER_UPDATE(next_op->_push_chunk_num_counter, 1);
                            COUNTER_UPDATE(next_op->_push_row_num_counter, row_num);
                        }

                        if (!return_status.ok() && !return_status.is_end_of_file()) {
                            LOG(WARNING) << "push_chunk returns not ok status " << return_status.to_string();
                            return return_status;
                        }
                    }
                    num_chunks_moved += 1;
                    total_chunks_moved += 1;
                }

                // Check curr_op finished again
                if (curr_op->is_epoch_finished()) {
                    if (i == 0) {
                        // For source operators
                        RETURN_IF_ERROR(return_status = _mark_operator_epoch_finishing(curr_op, runtime_state));
                    }
                    RETURN_IF_ERROR(return_status = _mark_operator_epoch_finishing(next_op, runtime_state));
                    new_first_epoch_unfinished = i + 1;
                    continue;
                }

                // Check curr_op finished again
                if (UNLIKELY(curr_op->is_finished())) {
                    // TODO: need add control flag
                    if (i == 0) {
                        // For source operators
                        RETURN_IF_ERROR(return_status = _mark_operator_finishing(curr_op, runtime_state));
                    }
                    RETURN_IF_ERROR(return_status = _mark_operator_finishing(next_op, runtime_state));
                    new_first_unfinished = i + 1;
                    continue;
                }
            }

            // TODO: Refine yield policy to be adaptive to StreamMV.
            {
                // yield when total chunks moved or time spent on-core for evaluation
                // exceed the designated thresholds.
                if (time_spent >= YIELD_MAX_TIME_SPENT) {
                    should_yield = true;
                    COUNTER_UPDATE(_yield_by_time_limit_counter, 1);
                    break;
                }
                if (_workgroup != nullptr && time_spent >= YIELD_PREEMPT_MAX_TIME_SPENT &&
                    _workgroup->driver_sched_entity()->in_queue()->should_yield(this, time_spent)) {
                    should_yield = true;
                    COUNTER_UPDATE(_yield_by_preempt_counter, 1);
                    break;
                }
            }
        }
        for (auto i = _first_epoch_unfinished; i < new_first_epoch_unfinished; ++i) {
            RETURN_IF_ERROR(return_status = _mark_operator_epoch_finished(_operators[i], runtime_state));
        }
        // If all operators are epoch finished, set the driver yield.
        if (!should_yield && new_first_epoch_unfinished == num_operators) {
            // TODO: Add a new profile type.
            COUNTER_UPDATE(_yield_by_preempt_counter, 1);
            should_yield = true;
        }

        // close finished operators and update _first_unfinished index
        for (auto i = _first_unfinished; i < new_first_unfinished; ++i) {
            RETURN_IF_ERROR(return_status = _mark_operator_finished(_operators[i], runtime_state));
        }
        _first_unfinished = new_first_unfinished;
        if (UNLIKELY(sink_operator()->is_finished())) {
            finish_operators(runtime_state);
            set_driver_state(is_still_pending_finish() ? DriverState::PENDING_FINISH : DriverState::FINISH);
            return _state;
        }

        // no chunk moved in current round means that the driver is blocked.
        // should yield means that the CPU core is occupied the driver for a
        // very long time so that the driver should switch off the core and
        // give chance for another ready driver to run.
        if (num_chunks_moved == 0 || should_yield) {
            if (is_precondition_block()) {
                set_driver_state(DriverState::PRECONDITION_BLOCK);
                COUNTER_UPDATE(_block_by_precondition_counter, 1);
            } else if (!sink_operator()->is_finished() && !sink_operator()->need_input()) {
                set_driver_state(DriverState::OUTPUT_FULL);
                COUNTER_UPDATE(_block_by_output_full_counter, 1);
            } else if (!source_operator()->is_finished() && !source_operator()->has_output()) {
                set_driver_state(DriverState::INPUT_EMPTY);
                COUNTER_UPDATE(_block_by_input_empty_counter, 1);
            } else {
                set_driver_state(DriverState::READY);
            }
            return _state;
        }
    }
}

Status StreamPipelineDriver::_mark_operator_epoch_finishing(OperatorPtr& op, RuntimeState* state) {
    auto& op_state = _operator_stages[op->get_id()];
    if (op_state >= OperatorStage::EPOCH_FINISHING) {
        return Status::OK();
    }

    VLOG_ROW << strings::Substitute("[Driver] epoch finishing operator [fragment_id=$0] [driver=$1] [operator=$2]",
                                    print_id(state->fragment_instance_id()), to_readable_string(), op->get_name());
    {
        SCOPED_TIMER(op->_finishing_timer);
        op_state = OperatorStage::EPOCH_FINISHING;
        QUERY_TRACE_SCOPED(op->get_name(), "set_epoch_finishing");
        return op->set_epoch_finishing(state);
    }
}

Status StreamPipelineDriver::_mark_operator_epoch_finished(OperatorPtr& op, RuntimeState* state) {
    RETURN_IF_ERROR(_mark_operator_epoch_finishing(op, state));
    auto& op_state = _operator_stages[op->get_id()];
    if (op_state >= OperatorStage::EPOCH_FINISHED) {
        return Status::OK();
    }

    VLOG_ROW << strings::Substitute("[Driver] epoch finished operator [fragment_id=$0] [driver=$1] [operator=$2]",
                                    print_id(state->fragment_instance_id()), to_readable_string(), op->get_name());
    {
        SCOPED_TIMER(op->_finished_timer);
        op_state = OperatorStage::EPOCH_FINISHED;
        QUERY_TRACE_SCOPED(op->get_name(), "set_epoch_finished");
        return op->set_epoch_finished(state);
    }
}

} // namespace starrocks::pipeline
